{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dashboards </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing Packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "from langdetect import lang_detect_exception\n",
    "from dash_bootstrap_templates import ThemeChangerAIO, template_from_url\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Cleaning </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "Tweet_Train = pd.DataFrame(pd.read_csv('twitter_training.csv'))\n",
    "#To rename the columns of the Tweet_Train and Tweet_Test DataFrames. \n",
    "headers=['Tweet ID', 'Entity', 'Sentiment', 'Content']\n",
    "Tweet_Train.columns = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove duplicate values\n",
    "Tweet_Train[Tweet_Train.duplicated(subset=['Content'], keep=False)]\n",
    "Tweet_Train_Clean= Tweet_Train.drop_duplicates(subset=['Content'], keep='first')\n",
    "#To remove missing values\n",
    "Tweet_Train_Clean=Tweet_Train_Clean.dropna()\n",
    "#To get the number of rows and columns in the clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data Transformation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a function to detect the language of a tweet and map to full language names\n",
    "def detect_language(tweet):\n",
    "    try:\n",
    "        lang_code = detect(tweet)\n",
    "        # Create a dictionary to map language abbreviations to full names\n",
    "        language_mapping = {\n",
    "            \"af\": \"Afrikaans\",\n",
    "            \"bg\": \"Bulgarian\",\n",
    "            \"ca\": \"Catalan\",\n",
    "            \"cs\": \"Czech\",\n",
    "            \"cy\": \"Welsh\",\n",
    "            \"da\": \"Danish\",\n",
    "            \"de\": \"German\",\n",
    "            \"en\": \"English\",\n",
    "            \"es\": \"Spanish\",\n",
    "            \"et\": \"Estonian\",\n",
    "            \"fi\": \"Finnish\",\n",
    "            \"fr\": \"French\",\n",
    "            \"hr\": \"Croatian\",\n",
    "            \"hu\": \"Hungarian\",\n",
    "            \"id\": \"Indonesian\",\n",
    "            \"it\": \"Italian\",\n",
    "            \"lt\": \"Lithuanian\",\n",
    "            \"lv\": \"Latvian\",\n",
    "            \"mk\": \"Macedonian\",\n",
    "            \"nl\": \"Dutch\",\n",
    "            \"no\": \"Norwegian\",\n",
    "            \"pl\": \"Polish\",\n",
    "            \"pt\": \"Portuguese\",\n",
    "            \"ro\": \"Romanian\",\n",
    "            \"ru\": \"Russian\",\n",
    "            \"sk\": \"Slovak\",\n",
    "            \"sl\": \"Slovenian\",\n",
    "            \"so\": \"Somali\",\n",
    "            \"sq\": \"Albanian\",\n",
    "            \"sv\": \"Swedish\",\n",
    "            \"sw\": \"Swahili\",\n",
    "            \"th\": \"Thai\",\n",
    "            \"tl\": \"Tagalog\",\n",
    "            \"tr\": \"Turkish\",\n",
    "            \"uk\": \"Ukrainian\",\n",
    "            \"vi\": \"Vietnamese\"\n",
    "        }\n",
    "        return language_mapping.get(lang_code, \"Unknown\")\n",
    "    except lang_detect_exception.LangDetectException:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# Apply the function to each tweet in the \"Content\" column and create a new \"Language\" column\n",
    "Tweet_Train_Clean[\"Language\"] = Tweet_Train_Clean[\"Content\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Entity Dashboard </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x22023861750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbc_css_1 = (\"https://cdn.jsdelivr.net/gh/AnnMarieW/dash-bootstrap-templates@V1.0.2/dbc.min.css\")\n",
    "\n",
    "# Create Dash app with VAPOR theme\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.VAPOR, dbc_css_1])\n",
    "\n",
    "# Language filter options\n",
    "language_options = [{'label': lang, 'value': lang} for lang in Tweet_Train_Clean['Language'].unique()]\n",
    "\n",
    "# Define a function to create KPIs\n",
    "def create_kpi(value, label):\n",
    "    return html.Div([\n",
    "        html.Div(value, className=\"kpi-value\"),\n",
    "        html.Div(label, className=\"kpi-label\"),\n",
    "    ], className=\"kpi\")\n",
    "\n",
    "#Initalizing Variables\n",
    "entity_count = len(Tweet_Train_Clean['Entity'])\n",
    "positive_count = len(Tweet_Train_Clean[Tweet_Train_Clean['Sentiment'] == 'Positive'])\n",
    "negative_count = len(Tweet_Train_Clean[Tweet_Train_Clean['Sentiment'] == 'Negative'])\n",
    "\n",
    "# Set up the app layout\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"Entity Dashboard\", className=\"mb-4\"),  \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='language-filter',\n",
    "                options=[{'label': 'All Languages', 'value': 'All'}] + language_options,\n",
    "                value=['All'],\n",
    "                multi=True,\n",
    "            ),\n",
    "            html.P(\"Select one or more languages:\", className=\"mb-2 text-muted\"),\n",
    "        ],\n",
    "        width=3),\n",
    "    ]),\n",
    "    dbc.Col([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.P(\"Total Entities:\", className=\"mb-2 text-muted\"),width=4),\n",
    "            dbc.Col(html.P(\"Total Positive Sentiments:\", className=\"mb-2 text-muted\"),width=4),\n",
    "            dbc.Col(html.P(\"Total Negative Sentiments:\", className=\"mb-2 text-muted\"),width=4),\n",
    "        ], className=\"mb-\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(create_kpi(f\"{entity_count}\", \"\"), width=4, id= 'entity-kpi'),\n",
    "            dbc.Col(create_kpi(f\"{positive_count}\", \"\"), width=4, id= 'positive-kpi'),\n",
    "            dbc.Col(create_kpi(f\"{negative_count}\", \"\"), width=4, id= 'negative-kpi'),\n",
    "        ], className=\"mb-2\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='Positive-Entity-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "            dbc.Col(dcc.Graph(id='Negative-Entity-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='Neutral-or-Irrelevant-Entity-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "            dbc.Col(dcc.Graph(id='Total-Entity-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "        ]),\n",
    "    ],\n",
    "    width=12),\n",
    "    ],\n",
    "    fluid=True,\n",
    "    className=\"dbc dbc-ag-grid\"\n",
    ")\n",
    "\n",
    "# Define a function to update the visualizations and KPIs\n",
    "def update_visualizations(selected_languages):\n",
    "    # Filter data based on selected languages\n",
    "    if 'All' in selected_languages:\n",
    "        filtered_data = Tweet_Train_Clean\n",
    "    else:\n",
    "        filtered_data = Tweet_Train_Clean[Tweet_Train_Clean['Language'].isin(selected_languages)] \n",
    "    \n",
    "    # Calculate entity_count, positive_count, and negative_count based on your data\n",
    "    entity_count = len(filtered_data['Entity'])\n",
    "    positive_count = len(filtered_data[filtered_data['Sentiment'] == 'Positive'])\n",
    "    negative_count = len(filtered_data[filtered_data['Sentiment'] == 'Negative'])\n",
    "  \n",
    "\n",
    "    # Create Positive Tweet line chart\n",
    "    # Calculate the total number of positive sentiment tweets for each entity\n",
    "    positive_tweets_by_entity_l1 = filtered_data[filtered_data['Sentiment'] == 'Positive'].groupby('Entity').size().reset_index(name='Positive Tweets by Entity')\n",
    "\n",
    "    # Calculate the total number of tweets for each entity\n",
    "    total_tweets_by_entity_l1 = filtered_data.groupby('Entity').size().reset_index(name='Total Tweets by Entity')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Language' column\n",
    "    merged_data_en_l1 = total_tweets_by_entity_l1.merge(positive_tweets_by_entity_l1, on='Entity')\n",
    "\n",
    "    # Calculate the percentage of positive sentiment tweets relative to total tweets for each entity\n",
    "    merged_data_en_l1['Positive Sentiment Percentage'] = (merged_data_en_l1['Positive Tweets by Entity'] / merged_data_en_l1['Total Tweets by Entity']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    positive_entity_fig = px.line(\n",
    "    merged_data_en_l1,\n",
    "    x='Entity',\n",
    "    y='Positive Sentiment Percentage',\n",
    "    title='Positive Sentiments Percentage by Entity',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "    # Create Negative Tweets line chart\n",
    "    # Calculate the total number of negative sentiment tweets for each entity\n",
    "    negative_tweets_by_entity_l2 = filtered_data[filtered_data['Sentiment'] == 'Negative'].groupby('Entity').size().reset_index(name='Negative Tweets by Entity')\n",
    "\n",
    "    # Calculate the total number of tweets for each entity\n",
    "    total_tweets_by_entity_l2 = filtered_data.groupby('Entity').size().reset_index(name='Total Tweets by Entity')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Entity' column\n",
    "    merged_data_en_l2 = total_tweets_by_entity_l2.merge(negative_tweets_by_entity_l2, on='Entity')\n",
    "\n",
    "    # Calculate the percentage of negative sentiment tweets relative to total tweets for each entity\n",
    "    merged_data_en_l2['Negative Sentiment Percentage'] = (merged_data_en_l2['Negative Tweets by Entity'] / merged_data_en_l2['Total Tweets by Entity']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    negative_entity_fig = px.line(\n",
    "    merged_data_en_l2,\n",
    "    x='Entity',\n",
    "    y='Negative Sentiment Percentage',\n",
    "    title='Negative Sentiments Percentage by Entity',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "    # Create Neutral or Irrelevant Tweet Line Chart\n",
    "    # Calculate the total number of neutral or irrelevant sentiment tweets for each entity\n",
    "    neutral_irrelevant_tweets_by_entity_l3 = filtered_data[filtered_data['Sentiment'].isin(['Neutral','Irrelevant'])].groupby('Entity').size().reset_index(name='Neutral or Irrelevant Tweets by Entity')\n",
    "\n",
    "    # Calculate the total number of tweets for each entity\n",
    "    total_tweets_by_entity_l3 = filtered_data.groupby('Entity').size().reset_index(name='Total Tweets by Entity')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Entity' column\n",
    "    merged_data_en_l3 = total_tweets_by_entity_l3.merge(neutral_irrelevant_tweets_by_entity_l3, on='Entity')\n",
    "\n",
    "    # Calculate the percentage of neutral or irrelevant sentiment tweets relative to total tweets for each entity\n",
    "    merged_data_en_l3['Neutral or Irrelevant Sentiment Percentage'] = (merged_data_en_l3['Neutral or Irrelevant Tweets by Entity'] / merged_data_en_l3['Total Tweets by Entity']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    neutral_irrelevant_entity_fig = px.line(\n",
    "    merged_data_en_l3,\n",
    "    x='Entity',\n",
    "    y='Neutral or Irrelevant Sentiment Percentage',\n",
    "    title='Neutral or Irrelevant Sentiments Percentage by Entity',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "    total_entity_fig = px.line(\n",
    "        filtered_data.groupby(['Entity']).size().reset_index(name='Overall Sentiments'),\n",
    "        x='Entity',\n",
    "        y='Overall Sentiments',\n",
    "        title='Entity with Overall Sentiments',\n",
    "        markers=True\n",
    "    )\n",
    "    # Adjusting the outlook of the figures\n",
    "    for fig in [positive_entity_fig, negative_entity_fig, neutral_irrelevant_entity_fig, total_entity_fig]:\n",
    "     fig.update_xaxes(showgrid=False)\n",
    "     fig.update_yaxes(showgrid=False)\n",
    "     fig.update_layout(\n",
    "        plot_bgcolor='rgb(26,9,51)',\n",
    "        paper_bgcolor='rgb(26,9,51)',\n",
    "        title_font=dict(size=20),\n",
    "        title_x=0.5,\n",
    "        font=dict(\n",
    "            family=\"Calibri\",  # Set the font family\n",
    "            size=12,  # Set the font size\n",
    "            color=\"rgb(50,251,226)\"  # Set the text color (e.g., \"red\")\n",
    "        )\n",
    "    )\n",
    "     fig.update_traces(\n",
    "        line=dict(color='rgb(50,251,226)'),  # Change line color to a specific RGB value\n",
    "        marker=dict(color='rgb(50,251,226)')  # Change marker color to a specific RGB value\n",
    "    )\n",
    "    return positive_entity_fig, negative_entity_fig, neutral_irrelevant_entity_fig, total_entity_fig, entity_count, positive_count, negative_count\n",
    "\n",
    "# Update the visualizations based on the language filter\n",
    "@app.callback(\n",
    "    [Output('Positive-Entity-Count', 'figure'),\n",
    "     Output('Negative-Entity-Count', 'figure'),\n",
    "     Output('Neutral-or-Irrelevant-Entity-Count', 'figure'),\n",
    "     Output('Total-Entity-Count', 'figure'),\n",
    "     Output('entity-kpi', 'children'),\n",
    "     Output('positive-kpi', 'children'),\n",
    "     Output('negative-kpi', 'children')],\n",
    "    [Input('language-filter', 'value')]\n",
    ")\n",
    "def update_visualizations_callback(selected_languages):\n",
    "    return update_visualizations(selected_languages)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, host='127.0.0.1', port=8051) #URL: http://127.0.0.1:8051/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Language Dashboard </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x220241dd790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbc_css_2 = (\"https://cdn.jsdelivr.net/gh/AnnMarieW/dash-bootstrap-templates@V1.0.2/dbc.min.css\")\n",
    "\n",
    "# Create Dash app with VAPOR theme\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.VAPOR, dbc_css_2])\n",
    "\n",
    "# Entity filter options\n",
    "entity_options = [{'label': entity, 'value': entity} for entity in Tweet_Train_Clean['Entity'].unique()]\n",
    "\n",
    "# Language filter options with only \"All\" and \"Exclude English\"\n",
    "language_options_2 = [{'label': 'All', 'value': 'All'}, {'label': 'Exclude English', 'value': 'ExcludeEnglish'}]\n",
    "\n",
    "# Define a function to create KPIs\n",
    "def create_kpi(value, label):\n",
    "    return html.Div([\n",
    "        html.Div(value, className=\"kpi-value\"),\n",
    "        html.Div(label, className=\"kpi-label\"),\n",
    "    ], className=\"kpi\")\n",
    "\n",
    "#Initalizing Variables\n",
    "language_count = len(Tweet_Train_Clean['Language'])\n",
    "positive_count_2 = len(Tweet_Train_Clean[Tweet_Train_Clean['Sentiment'] == 'Positive'])\n",
    "negative_count_2 = len(Tweet_Train_Clean[Tweet_Train_Clean['Sentiment'] == 'Negative'])\n",
    "\n",
    "# Set up the app layout\n",
    "app.layout = dbc.Container([\n",
    "    html.H1(\"Language Dashboard\", className=\"mb-4\"),  \n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='entity-filter',\n",
    "                options=[{'label': 'All Entities', 'value': 'All'}] + entity_options,\n",
    "                value=['All'],\n",
    "                multi=True,\n",
    "            ),\n",
    "            html.P(\"Select one or more entities:\", className=\"mb-2 text-muted\"),\n",
    "        ],\n",
    "        width=3),\n",
    "    dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='language-filter-2',\n",
    "                options=language_options_2,\n",
    "                value=['All'],\n",
    "                multi=False,\n",
    "            ),\n",
    "            html.P(\"Exclude English if needed:\", className=\"mb-2 text-muted\"),\n",
    "        ], width=3),\n",
    "    ]),\n",
    "\n",
    "    dbc.Col([\n",
    "        dbc.Row([\n",
    "            dbc.Col(html.P(\"Total Languages:\", className=\"mb-2 text-muted\"),width=4),\n",
    "            dbc.Col(html.P(\"Total Positive Sentiments:\", className=\"mb-2 text-muted\"),width=4),\n",
    "            dbc.Col(html.P(\"Total Negative Sentiments:\", className=\"mb-2 text-muted\"),width=4),\n",
    "        ], className=\"mb-1\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(create_kpi(f\"{language_count}\", \"\"), width=4,  id='language-kpi'),\n",
    "            dbc.Col(create_kpi(f\"{positive_count_2}\", \"\"), width=4, id='positive-kpi-2'),\n",
    "            dbc.Col(create_kpi(f\"{negative_count_2}\", \"\"), width=4, id='negative-kpi-2'),\n",
    "        ], className=\"mb-4\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='Positive-Language-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "            dbc.Col(dcc.Graph(id='Negative-Language-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.Graph(id='Neutral-or-Irrelevant-Language-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "            dbc.Col(dcc.Graph(id='Total-Language-Count'), width={\"size\": 6, \"offset\": 0}),\n",
    "        ]),\n",
    "    ],\n",
    "    width=12),\n",
    "    ],\n",
    "    fluid=True,\n",
    "    className=\"dbc dbc-ag-grid\"\n",
    ")\n",
    "\n",
    "# Define a function to update the visualizations and KPIs\n",
    "def update_visualizations_2(selected_entities, selected_languages_2):\n",
    "    # Filter data based on selected entities and language\n",
    "    if 'All' in selected_entities:\n",
    "        filtered_data = Tweet_Train_Clean\n",
    "    else:\n",
    "        filtered_data = Tweet_Train_Clean[Tweet_Train_Clean['Entity'].isin(selected_entities)]\n",
    "\n",
    "    if selected_languages_2 == 'ExcludeEnglish':\n",
    "        filtered_data = filtered_data[filtered_data['Language'] != 'English']\n",
    "\n",
    "    # Calculate language_count, positive_count, and negative_count based on your data\n",
    "    language_count = len(filtered_data['Language'])\n",
    "    positive_count = len(filtered_data[filtered_data['Sentiment'] == 'Positive'])\n",
    "    negative_count = len(filtered_data[filtered_data['Sentiment'] == 'Negative'])\n",
    "    \n",
    "    # Create Positive Tweet line chart\n",
    "    # Calculate the total number of positive sentiment tweets for each language\n",
    "    positive_tweets_by_language_l1 = filtered_data[filtered_data['Sentiment'] == 'Positive'].groupby('Language').size().reset_index(name='Positive Tweets by Language')\n",
    "\n",
    "    # Calculate the total number of tweets for each language\n",
    "    total_tweets_by_language_l1 = filtered_data.groupby('Language').size().reset_index(name='Total Tweets by Language')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Language' column\n",
    "    merged_data_l1 = total_tweets_by_language_l1.merge(positive_tweets_by_language_l1, on='Language')\n",
    "\n",
    "    # Calculate the percentage of positive sentiment tweets relative to total tweets for each language\n",
    "    merged_data_l1['Positive Sentiment Percentage'] = (merged_data_l1['Positive Tweets by Language'] / merged_data_l1['Total Tweets by Language']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    positive_language_fig = px.line(\n",
    "    merged_data_l1,\n",
    "    x='Language',\n",
    "    y='Positive Sentiment Percentage',\n",
    "    title='Positive Sentiments Percentage by Langugage',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create Negative Tweets line chart\n",
    "    # Calculate the total number of negative sentiment tweets for each language\n",
    "    negative_tweets_by_language_l2 = filtered_data[filtered_data['Sentiment'] == 'Negative'].groupby('Language').size().reset_index(name='Negative Tweets by Language')\n",
    "\n",
    "    # Calculate the total number of tweets for each language\n",
    "    total_tweets_by_language_l2 = filtered_data.groupby('Language').size().reset_index(name='Total Tweets by Language')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Language' column\n",
    "    merged_data_l2 = total_tweets_by_language_l2.merge(negative_tweets_by_language_l2, on='Language')\n",
    "\n",
    "    # Calculate the percentage of negative sentiment tweets relative to total tweets for each language\n",
    "    merged_data_l2['Negative Sentiment Percentage'] = (merged_data_l2['Negative Tweets by Language'] / merged_data_l2['Total Tweets by Language']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    negative_language_fig = px.line(\n",
    "    merged_data_l2,\n",
    "    x='Language',\n",
    "    y='Negative Sentiment Percentage',\n",
    "    title='Negative Sentiments Percentage by Langugage',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "    # Create Neutral or Irrelevant Tweet Line Chart\n",
    "    # Calculate the total number of neutral or irrelevant sentiment tweets for each language\n",
    "    neutral_irrelevant_tweets_by_language_l3 = filtered_data[filtered_data['Sentiment'].isin(['Neutral','Irrelevant'])].groupby('Language').size().reset_index(name='Neutral or Irrelevant Tweets by Language')\n",
    "\n",
    "    # Calculate the total number of tweets for each language\n",
    "    total_tweets_by_language_l3 = filtered_data.groupby('Language').size().reset_index(name='Total Tweets by Language')\n",
    "\n",
    "    # Merge the two dataframes based on the 'Language' column\n",
    "    merged_data_l3 = total_tweets_by_language_l3.merge(neutral_irrelevant_tweets_by_language_l3, on='Language')\n",
    "\n",
    "    # Calculate the percentage of neutral or irrelevant sentiment tweets relative to total tweets for each language\n",
    "    merged_data_l3['Neutral or Irrelevant Sentiment Percentage'] = (merged_data_l3['Neutral or Irrelevant Tweets by Language'] / merged_data_l3['Total Tweets by Language']) * 100\n",
    "\n",
    "    # Create the line chart\n",
    "    neutral_irrelevant_language_fig = px.line(\n",
    "    merged_data_l3,\n",
    "    x='Language',\n",
    "    y='Neutral or Irrelevant Sentiment Percentage',\n",
    "    title='Neutral or Irrelevant Sentiments Percentage by Language',\n",
    "    markers=True\n",
    "    )\n",
    "\n",
    "    total_language_fig = px.line(\n",
    "        filtered_data.groupby(['Language']).size().reset_index(name='Overall Sentiments'),\n",
    "        x='Language',\n",
    "        y='Overall Sentiments',\n",
    "        title='Overall Sentiments by Language',\n",
    "        markers=True\n",
    "    )\n",
    "    # Adjusting the outlook of the figures\n",
    "    for fig in [positive_language_fig, negative_language_fig, neutral_irrelevant_language_fig, total_language_fig]:\n",
    "     fig.update_xaxes(showgrid=False)\n",
    "     fig.update_yaxes(showgrid=False)\n",
    "     fig.update_layout(\n",
    "        plot_bgcolor='rgb(26,9,51)',\n",
    "        paper_bgcolor='rgb(26,9,51)',\n",
    "        title_font=dict(size=20),\n",
    "        title_x=0.5,\n",
    "        font=dict(\n",
    "            family=\"Calibri\",  # Set the font family\n",
    "            size=12,  # Set the font size\n",
    "            color=\"rgb(50,251,226)\"  # Set the text color\n",
    "        )\n",
    "    )\n",
    "     fig.update_traces(\n",
    "        line=dict(color='rgb(50,251,226)'),  # Change line color to a specific RGB value\n",
    "        marker=dict(color='rgb(50,251,226)')  # Change marker color to a specific RGB value\n",
    "    )\n",
    "    return positive_language_fig, negative_language_fig, neutral_irrelevant_language_fig, total_language_fig,language_count, positive_count, negative_count\n",
    "\n",
    "# Update the visualizations based on the language filter\n",
    "@app.callback(\n",
    "    [Output('Positive-Language-Count', 'figure'),\n",
    "     Output('Negative-Language-Count', 'figure'),\n",
    "     Output('Neutral-or-Irrelevant-Language-Count', 'figure'),\n",
    "     Output('Total-Language-Count', 'figure'),\n",
    "     Output('language-kpi', 'children'),\n",
    "     Output('positive-kpi-2', 'children'),\n",
    "     Output('negative-kpi-2', 'children')],\n",
    "    [Input('entity-filter', 'value'),\n",
    "     Input('language-filter-2', 'value')]\n",
    ")\n",
    "def update_visualizations_callback_2(selected_entities, selected_lanuages_2):\n",
    "    return update_visualizations_2(selected_entities, selected_lanuages_2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False, host='127.0.0.1', port=8052) #URL: http://127.0.0.1:8052/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Combined Dashboard </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8053/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2201b030150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbc_css_3 = (\"https://cdn.jsdelivr.net/gh/AnnMarieW/dash-bootstrap-templates@V1.0.2/dbc.min.css\")\n",
    "\n",
    "# Create Dash app with VAPOR theme\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.VAPOR, dbc_css_3])\n",
    "\n",
    "# Define the sidebar layout\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        html.H2(\"Sidebar\", className=\"display-4\"),\n",
    "        html.Hr(),\n",
    "        html.P(\"Choose a Dashboard:\", className=\"lead\"),\n",
    "        dcc.Link(\"Entity Dashboard\", href=\"/entity-dashboard\", style={\"color\": \"rgb(50,251,226)\"}),\n",
    "        html.Br(),\n",
    "        dcc.Link(\"Language Dashboard\", href=\"/language-dashboard\", style={\"color\": \"rgb(50,251,226)\"}),\n",
    "    ],\n",
    "    style={\n",
    "        \"position\": \"fixed\",\n",
    "        \"top\": 0,\n",
    "        \"left\": 0,\n",
    "        \"bottom\": 0,\n",
    "        \"width\": \"16rem\",\n",
    "        \"padding\": \"2rem 1rem\",\n",
    "        \"background-color\": \"rgb(26,9,51)\",  # To change the background color\n",
    "        \"color\": \"rgb(50,251,226)\",  # To change the text color\n",
    "        \"border\": \"2px solid rgb(50,251,226)\", #To add a coloured border\n",
    "    },\n",
    ")\n",
    "\n",
    "# Define the app layout\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id=\"url\"),\n",
    "    sidebar,\n",
    "    html.Div(id=\"page-content\", style={\"position\": \"absolute\", \"left\": \"18rem\", \"top\": 0, \"right\": 0, \"bottom\": 0}),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"page-content\", \"children\"),\n",
    "    [Input(\"url\", \"pathname\")]\n",
    ")\n",
    "def display_page(pathname):\n",
    "    if pathname == \"/entity-dashboard\":\n",
    "        return html.Iframe(src=\"http://127.0.0.1:8051/\", style={\"width\": \"100%\", \"height\": \"100vh\"})\n",
    "    elif pathname == \"/language-dashboard\":\n",
    "        return html.Iframe(src=\"http://127.0.0.1:8052/\", style={\"width\": \"100%\", \"height\": \"100vh\"})\n",
    "    else:\n",
    "        return \"Choose a Dashboard\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, port=8053)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
